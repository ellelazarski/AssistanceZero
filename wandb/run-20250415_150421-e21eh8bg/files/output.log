INFO - main - Starting training iteration 0
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
2025-04-15 15:39:21,293	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!
2025-04-15 15:39:21,641	WARNING replay_buffer.py:61 -- Estimated max memory usage for replay buffer is 18.672586752 GB (1024.0 batches of size 64, 18234948 bytes each), available system memory is 67.18121984 GB
2025-04-15 15:39:22,688	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.train_one_step` has been deprecated. This will raise an error in the future!
/home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
  F.linear(
/home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
  return F.linear(input, self.weight, self.bias)
2025-04-15 15:39:23,057	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/autograd/graph.py:823: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
INFO - main - Starting training iteration 1
INFO - main - Starting training iteration 2
INFO - main - Starting training iteration 3
INFO - main - Starting training iteration 4
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
2025-04-15 16:15:40,767	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 16:15:40,775	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000005
INFO - main - Starting training iteration 5
INFO - main - Starting training iteration 6
INFO - main - Starting training iteration 7
INFO - main - Starting training iteration 8
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 9
2025-04-15 16:51:28,812	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 16:51:28,819	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000010
INFO - main - Starting training iteration 10
INFO - main - Starting training iteration 11
INFO - main - Starting training iteration 12
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 13
INFO - main - Starting training iteration 14
2025-04-15 17:27:27,592	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 17:27:27,600	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000015
INFO - main - Starting training iteration 15
INFO - main - Starting training iteration 16
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 17
INFO - main - Starting training iteration 18
INFO - main - Starting training iteration 19
2025-04-15 18:03:27,050	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 18:03:27,057	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000020
INFO - main - Starting training iteration 20
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 21
INFO - main - Starting training iteration 22
INFO - main - Starting training iteration 23
INFO - main - Starting training iteration 24
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
2025-04-15 19:15:12,067	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 19:15:12,074	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000025
INFO - main - Starting training iteration 25
INFO - main - Starting training iteration 26
INFO - main - Starting training iteration 27
INFO - main - Starting training iteration 28
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 29
2025-04-15 19:51:21,324	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 19:51:21,331	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000030
INFO - main - Starting training iteration 30
INFO - main - Starting training iteration 31
INFO - main - Starting training iteration 32
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 33
INFO - main - Starting training iteration 34
2025-04-15 20:27:32,771	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 20:27:32,778	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000035
INFO - main - Starting training iteration 35
INFO - main - Starting training iteration 36
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 37
INFO - main - Starting training iteration 38
INFO - main - Starting training iteration 39
2025-04-15 21:03:34,766	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 21:03:34,773	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000040
INFO - main - Starting training iteration 40
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 41
INFO - main - Starting training iteration 42
INFO - main - Starting training iteration 43
INFO - main - Starting training iteration 44
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
2025-04-15 22:14:11,072	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 22:14:11,079	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000045
INFO - main - Starting training iteration 45
INFO - main - Starting training iteration 46
INFO - main - Starting training iteration 47
INFO - main - Starting training iteration 48
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 49
2025-04-15 22:50:07,237	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 22:50:07,245	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000050
INFO - main - Starting training iteration 50
INFO - main - Starting training iteration 51
INFO - main - Starting training iteration 52
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 53
INFO - main - Starting training iteration 54
2025-04-15 23:25:51,295	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-15 23:25:51,301	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000055
INFO - main - Starting training iteration 55
INFO - main - Starting training iteration 56
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 57
INFO - main - Starting training iteration 58
INFO - main - Starting training iteration 59
2025-04-16 00:01:53,073	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 00:01:53,081	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000060
INFO - main - Starting training iteration 60
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 61
INFO - main - Starting training iteration 62
INFO - main - Starting training iteration 63
INFO - main - Starting training iteration 64
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
2025-04-16 01:13:13,053	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 01:13:13,059	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000065
INFO - main - Starting training iteration 65
INFO - main - Starting training iteration 66
INFO - main - Starting training iteration 67
INFO - main - Starting training iteration 68
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 69
2025-04-16 01:49:10,257	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 01:49:10,264	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000070
INFO - main - Starting training iteration 70
INFO - main - Starting training iteration 71
INFO - main - Starting training iteration 72
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 73
INFO - main - Starting training iteration 74
2025-04-16 02:25:16,595	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 02:25:16,602	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000075
INFO - main - Starting training iteration 75
INFO - main - Starting training iteration 76
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 77
INFO - main - Starting training iteration 78
INFO - main - Starting training iteration 79
2025-04-16 03:01:19,273	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 03:01:19,279	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000080
INFO - main - Starting training iteration 80
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 81
INFO - main - Starting training iteration 82
INFO - main - Starting training iteration 83
INFO - main - Starting training iteration 84
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
2025-04-16 04:12:22,154	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 04:12:22,160	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000085
INFO - main - Starting training iteration 85
INFO - main - Starting training iteration 86
INFO - main - Starting training iteration 87
INFO - main - Starting training iteration 88
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 89
2025-04-16 04:48:20,865	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 04:48:20,872	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000090
INFO - main - Starting training iteration 90
INFO - main - Starting training iteration 91
INFO - main - Starting training iteration 92
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 93
INFO - main - Starting training iteration 94
2025-04-16 05:24:22,941	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 05:24:22,947	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000095
INFO - main - Starting training iteration 95
INFO - main - Starting training iteration 96
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/torch_models.py:84: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   F.linear(
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:144.)
[2m[36m(RolloutWorker pid=3721692)[0m   return F.linear(input, self.weight, self.bias)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/Documents/AssistanceZero/mbag/rllib/alpha_zero/alpha_zero_policy.py:585: RuntimeWarning: divide by zero encountered in log
[2m[36m(RolloutWorker pid=3721692)[0m   action_dist_inputs = np.log(mcts_policies)
[2m[36m(RolloutWorker pid=3721692)[0m /home/elle/miniconda3/envs/assistancezero/lib/python3.9/site-packages/gymnasium/spaces/box.py:230: UserWarning: [33mWARN: Casting input x to numpy array.[0m
[2m[36m(RolloutWorker pid=3721692)[0m   gym.logger.warn("Casting input x to numpy array.")
INFO - main - Starting training iteration 97
INFO - main - Starting training iteration 98
INFO - main - Starting training iteration 99
2025-04-16 06:00:24,903	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 06:00:24,909	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000100
2025-04-16 06:00:24,957	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
2025-04-16 06:00:24,961	WARNING policy.py:137 -- Can not figure out a durable policy name for <class 'mbag.rllib.alpha_zero.alpha_zero_policy.MbagAlphaZeroPolicy'>. You are probably trying to checkpoint a custom policy. Raw policy class may cause problems when the checkpoint needs to be loaded in the future. To fix this, make sure you add your custom policy in rllib.algorithms.registry.POLICIES.
INFO - main - Saved final checkpoint to data/logs/MbagAlphaZero/2_players/11x10x10/craftassist/alphazero_assistant/infinite_blocks_true/human_pikl/2025-04-15_15-04-16/1/checkpoint_000100
